---
title: "Independent Project."
author: "Simon Mmari"
date: '2022-03-23'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Define the question
The question is making conclusion on who is likely to click on the ads or not. 
## Metric for success

In order to work on the above problem, you need to do the following:
  
  -   Define the question, the metric for success, the context, experimental design taken and the appropriateness of the available data to answer the given question.

-   Find and deal with outliers, anomalies, and missing data within the dataset.

-   Perform univariate and bivariate analysis.

-   From your insights provide a conclusion and recommendation.


## Data Understanding (the context)

A Kenyan entrepreneur has created an online cryptography course and would want to advertise it on her blog. She currently targets audiences originating from various countries. In the past, she ran ads to advertise a related course on the same blog and collected data in the process. She would now like to employ your services as a Data Science Consultant to help her identify which individuals are most likely to click on her ads.

In order to work on the above problem, you need to do the following:
  
  -   Define the question, the metric for success, the context, experimental design taken and the appropriateness of the available data to answer the given question.

-   Find and deal with outliers, anomalies, and missing data within the dataset.

-   Perform univariate and bivariate analysis.

-   From your insights provide a conclusion and recommendation.

## Experimental design

1.  Import the data to R
2.  Perform data exploration
3.  Define metrics for success
4.  Perform Univariate and Bivariate data Analysis
5.  Provide conclusion

```{r}
ad <- read.csv("http://bit.ly/IPAdvertisingData")
```


```{r}
head(ad)
tail(ad)
```
```{r}
# Finding the Shape of the dataset
dim(ad)
```

```{r}
# Finding the datatypes of the dataset
str(ad)

```
## Data cleaning

```{r}
# checking for missing Data
colSums(is.na(ad))
```

```{r}
# Check for duplicated data in the ad
ad1 <- ad[duplicated(ad),]
ad1
```


```{r}
str(ad)
boxplot(ad$Daily.Time.Spent.on.Site, main = 'Daily Time Spent on-site')
boxplot(ad$Age, main = 'Age Boxplot')
boxplot(ad$Area.Income, main = 'Area Income Boxplot')
boxplot(ad$Daily.Internet.Usage, main = 'Daily Internet usage boxplot')
```
# print out the outliers
```{r}
boxplot(ad$Area.Income, main = 'Area Income Boxplot')$out
```


```{r}
ad[['Timestamp']] <- as.POSIXct(ad[['Timestamp']],
                                   format = "%Y-%m-%d %H:%M:%S")
```


## Univariate Analysis.

### Numerical columns.

```{r}
summary(ad)
```
There are outliers that do not look like they are in the extreme. There are areas where poverty is prevelant in such areas the total income could be that small.
#### Age 
# Mean.
```{r}
mean.age <- mean(ad$Age)
mean.age

```
# Function to get the mode.
```{r}
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

```

####Area income 
  
```{r}
mean.areaincome <- mean(ad$Area.Income)
mean.areaincome

```
```{r}
hist(ad$Area.Income,
     main="Histogram for Area Income", 
     xlab="Area income", 
     border="blue", 
     col="steelblue",)

```
#### Daily time spent on site

```{r}
mean.dtsos <- mean(ad$Daily.Time.Spent.on.Site)
mean.dtsos

````
```{r}
mode.dtsos <- getmode(ad$Daily.Time.Spent.on.Site)
mode.dtsos

```
#### Clicked.on.Ad

```{r}
uniq_clickers <- unique(ad$Clicked.on.Ad,)
length(uniq_clickers)

```
# There are two categories of the people who clicked on ads

Let us plot the frequency of each
```{r}
clickers <- ad$Clicked.on.Ad
clickers_frequency <- table (clickers)
barplot(clickers_frequency, col = "steelblue")

```
# There are 500 people who clicked on ads and another 500 did not click on the ads. 


### Categorical Columns.

```{r}

uniq_topic <- unique(ad$Ad.Topic.Line, )
length(uniq_topic)

```

# There are 1000 unique topic lines meaning it would be impossible to get a good visualization. 

#### Country 
```{r}
uniq_country <- unique(ad$Country)
length(uniq_country)

```
# There are 237 unique countries. 

````{r}
library(sf)
library(raster)
library(dplyr)
library(spData)
#library(spDataLarge)
library(tmap)
library(leaflet) 
library(ggplot2)

```

```{r}
Country <- ad$Country
countyfreq <- table(Country)

```


```{r}
hist(ad$`Age`, xlab = "Age")
# An even spread on time spent on site

```

```{r}

hist(ad$`Male`, xlab = "Male")

```

```{r}
age <- ad$Age
ages <- table(age)
barplot(ages, xlab = "Male")

# The age distribution

```

## Bivariate Analysis

# Lets find the covariance between a variety of the features 
```{r}
daily <- ad$`Daily Time Spent on Site`
age <- ad$Age
income <- ad$`Area Income`
sex <-ad$Male
use <- ad$`Daily Internet Usage`
click <- ad$`Clicked on Ad`
cov(daily,click)

#That has a negative correlation

```
## checking correlation matrix
```{r}
num_ads <- unlist(lapply(ad, is.numeric))
num_ad <- ad[ , num_ads]
cor(num_ad)

````


## Ploting age against clicks

```{r}
plot(click,age, xlab ="## Ploting age against clicks


(click,age, xlab = "Clicked on Ad", ylab = "The ones who clicked")

#The graph inst the best visual

```
### only the ones with postive correlations

```{r}
cor(age,click)

#a medium postive correlation 

```
#### Correlation
#creating with only interger columns
```{r}
numerical_df = ad[c("Daily.Time.Spent.on.Site", "Age", "Area.Income","Daily.Internet.Usage" ,"Male", "Clicked.on.Ad" )]
head(numerical_df)

```

```{r}
correlation = cor(numerical_df)
correlation

```

# KNN.

```{r}

require("datasets")


```


```{r}

ad1.encod <- ad
````

```{r}
colSums(is.na(ad))

```

```{r}
# Applying the K-means clustering algorithm with no. of centroids(k)=3
# ---
# 
ad.new<- ad
ad.class<- ad[, "Age"]
head(ad.new)
```

```{r}

normalize <- function(x){
  return ((x-min(x)) / (max(x)-min(x)))
}

```


```{r}

# Applying the K-means clustering algorithm with no. of centroids(k)=3
# ---
# 
result<- kmeans(ad.new,2) 

```

# Heirarchical Clustering.

```{r}
# Loading the data set
# ---
#
data("USArrests")

```


```{r}

b <- dist(ad1.encod, method = "euclidean")

```


```{r}
# We then hierarchical clustering using the Ward's method
# ---
# 
res.hc <- hclust(b, method = "ward.D2" )
res.hc
```

```{r}

# plotting the obtained dendrogram
# ---
# 
plot(res.hc, cex = 0.6, hang = -1)


```


### SVM
```{r}
library('caret')
intrain <- createDataPartition(y = ad$Clicked.on.Ad, p= 0.7, list = FALSE)
training <- ad[intrain,]
testing <- ad[-intrain,]
dim(training)
dim(testing)
```

```{r}
#building our model
# 
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
svm_Linear <- train(Clicked.on.Ad ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
svm_Linear
```

```{r}
#making predictions
test_pred <- predict(svm_Linear, newdata = testing)
test_pred
```

```{r}
#checking accuracy of model
confusionMatrix(table(test_pred, testing$Clicked.on.Ad))
```

```{r}
#Hyperparameter tuning
grid <- expand.grid(C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2,5))
svm_Linear_Grid <- train(Clicked.on.Ad ~., data = training, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneGrid = grid,
tuneLength = 10)
svm_Linear_Grid
plot(svm_Linear_Grid)
```

```{r}
#Making predictions with the model after tuning.
test_pred_grid <- predict(svm_Linear_Grid, newdata = testing)
test_pred_grid
```

```{r}
#checking the accuracy
confusionMatrix(table(test_pred_grid, testing$Clicked.on.Ad))
```


# Conclusion

* The age and gender do not determine whether an individual clicks on an ad. This is probably because their interests on the internet are different from what the ad is about.

* Daily time spent on a site has a negative correlation on whether an individual clicks on an ad probably because they are already on the site and are aware of what the ad is about.

* The model created using SVM performs good with an accuracy of 95.6%


* We achieved our metric of success since both our models achieved an accuracy score of above 85%.



# Recommendations


* Ads that are more appealing could be created so as to increase the ad clicks from men.

*  We recommend the use of the SVM model in making predictions as it achieved the highest accuracy score of 95.6%.

##9. Follow up questions

###a) Did we have the right data?
``` Yes we did. Our data set had a good number of variables that helped us study the individuals and determine who was likely to click on an ad..```
###b) Do we need other data to answer our question?
``` Not necessarily, however further research is needed to help gain deeper insight on the study.```

